# Importerar n√∂dv√§ndiga bibliotek och moduler
import streamlit as st  # F√∂r att bygga webbapplikationen
from dotenv import load_dotenv # F√∂r att ladda milj√∂variabler fr√•n en .env-fil
import os # F√∂r operativsysteminteraktioner, t.ex. filhantering
import requests # F√∂r att g√∂ra HTTP-anrop (anv√§nds h√§r f√∂r Lottie-animationen)

# Importerar anpassade funktioner f√∂r RAGAS (Retrieval Augmented Generation Assessment) och LLM (Large Language Model)
from utils.evaluation_utils import ragas_evaluate # Funktion f√∂r att utv√§rdera RAG-systemet
from core.gpt_logic import (
    search_relevant_chunks,    # Funktion f√∂r att hitta relevanta textdelar (chunks)
    generate_gpt_answer,       # Funktion f√∂r att generera svar med GPT
    chunk_text,                # Funktion f√∂r att dela upp text i mindre delar
    full_rapportanalys         # Funktion f√∂r att g√∂ra en fullst√§ndig rapportanalys
)
from core.embedding_utils import get_embedding # Funktion f√∂r att skapa text-embeddings

# Importerar anpassade funktioner f√∂r fil- och datahantering
from core.file_processing import extract_text_from_file # Funktion f√∂r att extrahera text fr√•n olika filtyper
from utils.cache_utils import get_embedding_cache_name, save_embeddings, load_embeddings_if_exists # Funktioner f√∂r att hantera cachning av embeddings
from utils.ocr_utils import extract_text_from_image_or_pdf # Funktion f√∂r att extrahera text fr√•n bilder eller PDFer med OCR
from utils.pdf_utils import answer_to_pdf # Funktion f√∂r att konvertera text till PDF
from utils.file_utils import save_output_file, save_uploaded_file # Funktioner f√∂r att spara filer
from services.html_downloader import fetch_html_text # Funktion f√∂r att h√§mta textinneh√•ll fr√•n en HTML-l√§nk

# Importerar bibliotek f√∂r Lottie-animationen
from streamlit_lottie import st_lottie # Komponent f√∂r att visa Lottie-animationer i Streamlit
import traceback # F√∂r att f√• detaljerad felinformation vid undantag

# --- Skapa n√∂dv√§ndiga datamappar ---
# Ser till att kataloger f√∂r lagring av embeddings, output-filer och uppladdade filer existerar.
# exist_ok=True f√∂rhindrar fel om mapparna redan finns.
for d in ["data/embeddings", "data/outputs", "data/uploads"]:
    os.makedirs(d, exist_ok=True)

# Laddar milj√∂variabler fr√•n .env-filen (t.ex. API-nycklar)
load_dotenv()

# Konfigurerar Streamlit-sidans titel och layout
st.set_page_config(page_title="ü§ñ AI Rapportanalys", layout="wide")

# --- UI Start ---
# Skapar kolumner f√∂r att centrera Lottie-animationen
col1_lottie, col2_lottie, col3_lottie = st.columns([3, 4, 3])
with col2_lottie:
    # URL till Lottie-animationen
    lottie_url = "https://raw.githubusercontent.com/siffror/ai-rapportanalys/main/1GRWuk0lXN.json"
    try:
        # F√∂rs√∂ker h√§mta Lottie-animationen fr√•n URL:en med en timeout
        r = requests.get(lottie_url, timeout=10)
        r.raise_for_status() # Genererar ett undantag om HTTP-anropet misslyckades (t.ex. 404, 500)
        lottie_json = r.json() # Tolkar svaret som JSON
        # Visar Lottie-animationen i Streamlit-appen
        st_lottie(lottie_json, speed=1, width=240, height=240, loop=True, quality="high", key="ai_logo")
    except requests.exceptions.RequestException as e_req:
        # Visar en varning om animationen inte kunde laddas p.g.a. n√§tverksfel
        st.warning(f"Kunde inte ladda AI-animationen (n√§tverksfel): {e_req}")
    except requests.exceptions.JSONDecodeError as e_json_lottie:
        # Visar en varning om animationen inte kunde tolkas som JSON
        st.warning(f"Kunde inte tolka AI-animationen (JSON-fel): {e_json_lottie}")

# Visar huvudtiteln f√∂r applikationen med anpassad HTML-styling
st.markdown("<h1 style='color:#3EA6FF;'>ü§ñ AI-baserad Rapportanalys</h1>", unsafe_allow_html=True)

# --- Sidomenyn √§r borttagen ---
# (Ingen kod h√§r, men kommentaren indikerar att sidomenyn avsiktligt inte anv√§nds)

# --- Huvudinneh√•ll: Input f√∂r rapportanalys ---
st.header("üìÑ Mata in rapporttext") # Rubrik f√∂r inmatningssektionen
# Skapar tv√• kolumner f√∂r att organisera inmatningsf√§lten
input_col1, input_col2 = st.columns(2)

with input_col1:
    # Textinmatningsf√§lt f√∂r HTML-l√§nk
    html_link = st.text_input("üåê Klistra in HTML-l√§nk till rapport (valfritt):", key="html_link_input")
    # Filuppladdare f√∂r olika filtyper
    uploaded_file = st.file_uploader("üìé Eller ladda upp rapportfil:",
                                     type=["pdf", "txt", "html", "docx", "md", "png", "jpg", "jpeg"], key="file_uploader_input")
with input_col2:
    # Textomr√•de f√∂r manuell inmatning av text
    manual_text_input = st.text_area("‚úèÔ∏è Eller klistra in text manuellt h√§r (valfritt):", height=205, key="manual_text_input_area")

# Initierar variabler f√∂r text som ska analyseras
preview_text, ocr_extracted_text = "", ""

# Logik f√∂r att hantera den uppladdade filen
if uploaded_file:
    # Kontrollerar om filen √§r en bild (f√∂r OCR)
    if uploaded_file.name.endswith((".png", ".jpg", ".jpeg")):
        # Extraherar text fr√•n bilden med OCR
        ocr_extracted_text, _ = extract_text_from_image_or_pdf(uploaded_file)
        if ocr_extracted_text:
            # Visar en f√∂rhandsgranskning av den OCR-extraherade texten (max 2000 tecken)
            st.expander("üñºÔ∏è OCR-utl√§st text (f√∂rhandsvisning)").text(ocr_extracted_text[:2000])
        else:
            st.warning("Kunde inte extrahera text med OCR fr√•n bilden.")
    else:
        # Extraherar text fr√•n andra filtyper (PDF, TXT, DOCX etc.)
        preview_text = extract_text_from_file(uploaded_file)
elif html_link:
    # H√§mtar textinneh√•ll fr√•n den angivna HTML-l√§nken
    preview_text = fetch_html_text(html_link)

# Best√§mmer vilken text som ska anv√§ndas f√∂r analysen baserat p√• anv√§ndarens input
# Prioriteringsordning: manuell inmatning, sedan text fr√•n uppladdad fil/HTML-l√§nk (inklusive OCR)
text_to_analyze = manual_text_input or preview_text or ocr_extracted_text

# Visar en f√∂rhandsgranskning av texten som kommer att analyseras
if text_to_analyze:
    st.expander("üìú Text som kommer att analyseras (f√∂rhandsvisning)", expanded=False).text(text_to_analyze[:3000])
else:
    # Informerar anv√§ndaren om att input beh√∂vs f√∂r att starta analysen
    st.info("‚ÑπÔ∏è Ange en rapport via l√§nk, filuppladdning eller inklistrad text f√∂r att kunna starta en analys.")

# --- Analysalternativ med Tabs ---
st.header("‚öôÔ∏è V√§lj Analysmetod") # Rubrik f√∂r val av analysmetod
# Skapar tv√• flikar: en f√∂r fullst√§ndig rapportanalys och en f√∂r fr√•gebaserad analys (RAG)
tab_full_analysis, tab_rag_analysis = st.tabs(["üîç Fullst√§ndig Rapportanalys", "üí¨ St√§ll en Fr√•ga till Rapporten"])

# Inneh√•ll f√∂r fliken "Fullst√§ndig Rapportanalys"
with tab_full_analysis:
    # Knapp f√∂r att starta den fullst√§ndiga analysen
    if st.button("Starta fullst√§ndig analys", use_container_width=True, key="btn_full_analysis_tab_main"):
        # Kontrollerar om det finns tillr√§ckligt med text f√∂r analys
        if text_to_analyze and len(text_to_analyze.strip()) > 20:
            # Visar en spinner medan GPT analyserar rapporten
            with st.spinner("üìä GPT analyserar hela rapporten..."):
                # Anropar funktionen f√∂r fullst√§ndig rapportanalys
                ai_report_content = full_rapportanalys(text_to_analyze)
                # Sparar resultatet i session state f√∂r att kunna √•teranv√§ndas (t.ex. f√∂r nedladdning)
                st.session_state['ai_report_content'] = ai_report_content
                # Visar rubrik och den genererade AI-analysen
                st.markdown("### üßæ Fullst√§ndig AI-analys:")
                st.markdown(st.session_state['ai_report_content'])
        else:
            # Visar ett felmeddelande om ingen text finns eller om texten √§r f√∂r kort
            st.error("Ingen text tillg√§nglig f√∂r fullst√§ndig analys, eller texten √§r f√∂r kort.")

    # Om en fullst√§ndig analys har genererats och finns i session state
    if 'ai_report_content' in st.session_state and st.session_state['ai_report_content']:
        # Visar en nedladdningsknapp f√∂r att spara analysen som PDF
        st.download_button(label="Ladda ner fullst√§ndig analys som PDF",
                            data=answer_to_pdf(st.session_state['ai_report_content']), # Konverterar analysen till PDF-format
                            file_name="ai_full_analys.pdf",
                            mime="application/pdf",
                            use_container_width=True,
                            key="dl_full_report_pdf_tab_main")

# Inneh√•ll f√∂r fliken "St√§ll en Fr√•ga till Rapporten" (RAG-analys)
with tab_rag_analysis:
    # Initierar en exempelfr√•ga i session state om den inte redan finns
    if "user_question_rag_tab" not in st.session_state:
        st.session_state.user_question_rag_tab = "Vilken utdelning per aktie f√∂resl√•s f√∂r n√§sta √•r?"
    # Textinmatningsf√§lt f√∂r anv√§ndarens specifika fr√•ga
    st.text_input("Din specifika fr√•ga om rapporten:", key="user_question_rag_tab")

    # Knapp f√∂r att starta den fr√•gebaserade analysen
    if st.button("Starta fr√•gebaserad analys", key="btn_rag_analysis_tab_main", use_container_width=True):
        # Kontrollerar om det finns tillr√§ckligt med text f√∂r analys
        if text_to_analyze and len(text_to_analyze.strip()) > 20:
            # Visar en spinner medan GPT s√∂ker och analyserar
            with st.spinner("ü§ñ GPT s√∂ker och analyserar baserat p√• din fr√•ga..."):
                # Skapar en unik identifierare f√∂r k√§llan (anv√§nds f√∂r cachning av embeddings)
                source_id = (html_link or (uploaded_file.name if uploaded_file else text_to_analyze[:50])) + "_embeddings_v5"
                # H√§mtar namnet p√• cache-filen f√∂r embeddings
                cache_file = get_embedding_cache_name(source_id)
                # F√∂rs√∂ker ladda f√∂rber√§knade embeddings fr√•n cache
                embedded_chunks = load_embeddings_if_exists(cache_file)

                # Om inga cachade embeddings hittades
                if not embedded_chunks:
                    st.info("Skapar och cachar text-embeddings (kan ta en stund f√∂r stora dokument)...")
                    # Delar upp texten i mindre "chunks"
                    chunks = chunk_text(text_to_analyze)
                    embedded_chunks = [] # Lista f√∂r att lagra textdelar och deras embeddings
                    if chunks:
                        # Visar en progress bar f√∂r bearbetningen av textblock
                        progress_bar = st.progress(0, text="Bearbetar textblock...")
                        for i, chunk_content in enumerate(chunks, 1):
                            try:
                                # Skapar embedding f√∂r varje textblock
                                embedding = get_embedding(chunk_content)
                                embedded_chunks.append({"text": chunk_content, "embedding": embedding})
                                # Uppdaterar progress bar
                                progress_bar.progress(i / len(chunks), text=f"Bearbetar textblock {i}/{len(chunks)}")
                            except Exception as e_emb:
                                # Hanterar fel som kan uppst√• vid skapande av embeddings
                                st.error(f"‚ùå Fel vid embedding av chunk {i}: {e_emb}")
                                st.stop() # Avbryter k√∂rningen vid fel
                        # Sparar de nyskapade embeddings till cache-filen
                        save_embeddings(cache_file, embedded_chunks)
                        progress_bar.empty() # Tar bort progress bar
                        st.success("Embeddings skapade och cachade!")
                    else:
                        # Varnar om inga textblock kunde skapas
                        st.warning("Kunde inte skapa n√•gra textblock (chunks) fr√•n den angivna texten.")
                        st.stop() # Avbryter k√∂rningen

                # Om inga embeddings finns (antingen fr√•n cache eller nyskapade)
                if not embedded_chunks:
                    st.error("Inga embeddings tillg√§ngliga f√∂r analys.")
                    st.stop() # Avbryter k√∂rningen

                # S√∂ker efter de mest relevanta textblocken baserat p√• anv√§ndarens fr√•ga och de skapade embeddings
                retrieved_context, top_chunks_details = search_relevant_chunks(
                    st.session_state.user_question_rag_tab, embedded_chunks
                )

                # Visar den relevanta kontexten som kommer att skickas till GPT (max 2000 tecken)
                st.expander("Relevant kontext som skickas till GPT").code(retrieved_context[:2000], language="text")

                # Den slutgiltiga fr√•gan som skickas till GPT √§r anv√§ndarens fr√•ga.
                # Ingen ytterligare prompt-modifiering sker h√§r i denna version.
                final_question_for_rag = st.session_state.user_question_rag_tab
                
                # Kommentar: Denna expander kan anv√§ndas f√∂r att visa den exakta fr√•gan som skickas till GPT.
                # st.expander("Slutgiltig fr√•ga som skickas till GPT").caption(final_question_for_rag)

                # Genererar ett svar fr√•n GPT baserat p√• fr√•gan och den h√§mtade kontexten
                rag_answer_content = generate_gpt_answer(final_question_for_rag, retrieved_context)
                # Sparar RAG-svaret i session state
                st.session_state['rag_answer_content'] = rag_answer_content

                # Visar GPT:s svar
                st.markdown(f"### ü§ñ GPT-svar:\n{rag_answer_content}")

                # Om ett RAG-svar har genererats
                if rag_answer_content:
                    st.markdown("--- \n ### Automatisk AI-evaluering (RAGAS):") # Rubrik f√∂r RAGAS-utv√§rdering
                    # Utv√§rderar kvaliteten p√• RAG-svaret med RAGAS
                    ragas_result = ragas_evaluate(
                        st.session_state.user_question_rag_tab, # Anv√§ndarens fr√•ga
                        rag_answer_content,                     # GPT:s svar
                        [chunk_text_content for _, chunk_text_content in top_chunks_details] # Textinneh√•llet fr√•n de relevanta chunks
                    )
                    # Hanterar resultatet fr√•n RAGAS-utv√§rderingen
                    if ragas_result and "error" in ragas_result:
                        st.info(f"(RAGAS) Kunde inte utv√§rdera svaret: {ragas_result['error']}")
                    elif ragas_result:
                        # H√§mtar RAGAS-metrics: Faithfulness och Answer Relevancy
                        faith_score = ragas_result.get('faithfulness')
                        ans_rel_score = ragas_result.get('answer_relevancy')
                        # Visar RAGAS-metrics i tv√• kolumner
                        col_ragas1, col_ragas2 = st.columns(2)
                        with col_ragas1:
                            st.metric("Faithfulness", f"{faith_score:.2f}" if faith_score is not None else "N/A",
                                      help="M√§ter hur v√§l AI:ns svar grundar sig p√• den information som h√§mtats fr√•n rapporten (0-1). H√∂gre √§r b√§ttre.")
                        with col_ragas2:
                            st.metric("Answer Relevancy", f"{ans_rel_score:.2f}" if ans_rel_score is not None else "N/A",
                                      help="M√§ter hur relevant AI:ns svar √§r p√• den st√§llda fr√•gan (0-1). H√∂gre √§r b√§ttre.")
        else:
            # Visar ett felmeddelande om ingen text finns eller om texten √§r f√∂r kort f√∂r RAG-analys
            st.error("Ingen text tillg√§nglig f√∂r fr√•gebaserad analys, eller s√• √§r texten f√∂r kort.")

    # Om ett RAG-svar finns i session state
    if 'rag_answer_content' in st.session_state and st.session_state['rag_answer_content']:
        st.markdown("---") # Horisontell linje
        st.subheader("‚¨áÔ∏è Exportera GPT-fr√•gesvar") # Rubrik f√∂r exportalternativ
        # Skapar tv√• kolumner f√∂r nedladdningsknappar
        col_export_rag1, col_export_rag2 = st.columns(2)
        with col_export_rag1:
            # Knapp f√∂r att ladda ner RAG-svaret som en .txt-fil
            st.download_button(
                "üíæ Ladda ner svar (.txt)",
                st.session_state['rag_answer_content'],
                file_name="gpt_fr√•gesvar.txt",
                key="dl_gpt_txt_rag_tab_main",
                use_container_width=True
            )
        with col_export_rag2:
            # Knapp f√∂r att ladda ner RAG-svaret som en .pdf-fil
            st.download_button(
                "üìÑ Ladda ner svar (.pdf)",
                answer_to_pdf(st.session_state['rag_answer_content']), # Konverterar svaret till PDF
                file_name="gpt_fr√•gesvar.pdf",
                key="dl_gpt_pdf_rag_tab_main",
                use_container_width=True
            )
